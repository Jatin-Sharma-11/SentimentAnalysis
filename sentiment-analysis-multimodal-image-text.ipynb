{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbf8fb0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:50.809797Z",
     "iopub.status.busy": "2024-12-29T18:56:50.809489Z",
     "iopub.status.idle": "2024-12-29T18:56:59.106262Z",
     "shell.execute_reply": "2024-12-29T18:56:59.105606Z"
    },
    "papermill": {
     "duration": 8.304785,
     "end_time": "2024-12-29T18:56:59.107919",
     "exception": false,
     "start_time": "2024-12-29T18:56:50.803134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from  matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cccccd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.118898Z",
     "iopub.status.busy": "2024-12-29T18:56:59.118406Z",
     "iopub.status.idle": "2024-12-29T18:56:59.121891Z",
     "shell.execute_reply": "2024-12-29T18:56:59.121280Z"
    },
    "papermill": {
     "duration": 0.009884,
     "end_time": "2024-12-29T18:56:59.123108",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.113224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mvsa_single_data_path = '../input/mvsasingle/MVSA_Single/data'\n",
    "mvsa_single_label_path = '../input/mvsasingle/MVSA_Single/labelResultAll.txt'\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbec839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.133530Z",
     "iopub.status.busy": "2024-12-29T18:56:59.133274Z",
     "iopub.status.idle": "2024-12-29T18:56:59.138335Z",
     "shell.execute_reply": "2024-12-29T18:56:59.137755Z"
    },
    "papermill": {
     "duration": 0.011829,
     "end_time": "2024-12-29T18:56:59.139685",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.127856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_text_file(path, multi_line=False):\n",
    "#     if multi_line == True:\n",
    "#         lines = open(path, 'r', encoding='latin-1').readlines()\n",
    "#         lines = [line.rstrip('\\n') for line in lines]\n",
    "#         return lines\n",
    "    return open(path, 'r', encoding='latin-1').read()\n",
    "\n",
    "def read_image_file(path):\n",
    "    try:\n",
    "        image = cv2.imread(path)[:, :, ::-1] #, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#         image = tf.keras.utils.load_img(path, target_size=IMAGE_SIZE)\n",
    "#         image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        invalid_ID = -1\n",
    "    except:\n",
    "        image = np.zeros((IMAGE_SIZE[0], IMAGE_SIZE[1], NUM_CHANNELS))\n",
    "        invalid_ID = int(os.path.split(path)[1].split('.')[0])\n",
    "    return image, invalid_ID\n",
    "\n",
    "def read_labels_file(path):\n",
    "    dataframe = pd.read_csv(path, sep=\"\\s+|,\", engine=\"python\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083da6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.149953Z",
     "iopub.status.busy": "2024-12-29T18:56:59.149741Z",
     "iopub.status.idle": "2024-12-29T18:56:59.154559Z",
     "shell.execute_reply": "2024-12-29T18:56:59.153917Z"
    },
    "papermill": {
     "duration": 0.011049,
     "end_time": "2024-12-29T18:56:59.155755",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.144706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_paths(path, extension):\n",
    "    ''' Get list of data paths with input extension and sort by its filename (ID)\n",
    "    path: Folder path\n",
    "    extension: File extension wants to get\n",
    "    '''\n",
    "    paths = os.listdir(path)\n",
    "    paths = list(filter(lambda x: x.endswith(extension), paths))\n",
    "    paths.sort(key = lambda x : int(x.split('.')[0]))\n",
    "    paths = [os.path.join(path, x) for x in paths]\n",
    "    return paths\n",
    "\n",
    "def get_image_with_id(path):\n",
    "    filename = os.path.split(path)[1]\n",
    "    ID = int(filename.split('.')[0])\n",
    "    image = read_image_file(path)\n",
    "    return (ID, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14fee83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.165756Z",
     "iopub.status.busy": "2024-12-29T18:56:59.165500Z",
     "iopub.status.idle": "2024-12-29T18:56:59.172198Z",
     "shell.execute_reply": "2024-12-29T18:56:59.171616Z"
    },
    "papermill": {
     "duration": 0.013045,
     "end_time": "2024-12-29T18:56:59.173395",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.160350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# there are 3 annotators labelling each modality labels in the MVSA-Multiple dataset\n",
    "# merge those 3 label pairs into 1 pair by taking majority vote on each modality label\n",
    "# since there are only 3 different labels, if 1 modality receives 3 different labels from 3 annotators\n",
    "# => the data pair contains it is considered invalid\n",
    "def merge_multi_label(dataframe):\n",
    "    anno_1 = list(dataframe.loc[:, ['text', 'image']].itertuples(index=False, name=None))\n",
    "    anno_2 = list(dataframe.loc[:, ['text.1', 'image.1']].itertuples(index=False, name=None))\n",
    "    anno_3 = list(dataframe.loc[:, ['text.2', 'image.2']].itertuples(index=False, name=None))\n",
    "    IDs = list(dataframe.iloc[:, 0])\n",
    "    \n",
    "    valid_pairs = []\n",
    "    \n",
    "    for i in range(len(anno_1)):\n",
    "        pairs = [anno_1[i], anno_2[i], anno_3[i]]\n",
    "        ID = IDs[i]\n",
    "        \n",
    "        text_labels = [pair[0] for pair in pairs]\n",
    "        image_labels = [pair[1] for pair in pairs]\n",
    "        \n",
    "        max_occur_text_label = max(text_labels, key=text_labels.count)\n",
    "        max_occur_image_label = max(image_labels, key=image_labels.count)\n",
    "\n",
    "        if text_labels.count(max_occur_text_label) > 1 and image_labels.count(max_occur_image_label) > 1:\n",
    "            valid_pair = (ID, max_occur_text_label, max_occur_image_label)\n",
    "        else:\n",
    "            valid_pair = (ID, 'invalid', 'invalid')\n",
    "        valid_pairs.append(valid_pair)\n",
    "    valid_dataframe = pd.DataFrame(valid_pairs, columns=['ID', 'text', 'image'])\n",
    "    return valid_dataframe\n",
    "\n",
    "def multimodal_label(text_label, image_label):\n",
    "    if text_label == image_label:\n",
    "        label = text_label\n",
    "    elif (text_label == 'positive' and image_label == 'negative') or (text_label == 'negative' and image_label == 'positive'):\n",
    "        label = 'invalid'\n",
    "    elif (text_label == 'neutral' and image_label != 'neutral') or (text_label != 'neutral' or image_label == 'neutral'):\n",
    "        label = image_label if text_label == 'neutral' else text_label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb91aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.183219Z",
     "iopub.status.busy": "2024-12-29T18:56:59.182981Z",
     "iopub.status.idle": "2024-12-29T18:56:59.189768Z",
     "shell.execute_reply": "2024-12-29T18:56:59.188974Z"
    },
    "papermill": {
     "duration": 0.013076,
     "end_time": "2024-12-29T18:56:59.191083",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.178007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_multimodal_labels(path, multiple=False, mappings=False):\n",
    "    dataframe = read_labels_file(path)\n",
    "    \n",
    "    if multiple == True:\n",
    "        dataframe = merge_multi_label(dataframe)\n",
    "\n",
    "    labels = []\n",
    "    for label_pair in dataframe.loc[:, ['text', 'image']].values:\n",
    "        label = multimodal_label(label_pair[0], label_pair[1])\n",
    "        labels.append(label)\n",
    "        \n",
    "    if mappings == True:\n",
    "        label_map = {}\n",
    "        for i in range(len(labels)):\n",
    "            ID = dataframe.iloc[i, 0]\n",
    "            label_map[ID] = labels[i]            \n",
    "        return label_map\n",
    "    \n",
    "    return np.array(labels, dtype='object')\n",
    "\n",
    "def create_original_labels(path, multiple=False):\n",
    "    dataframe = read_labels_file(path)\n",
    "    \n",
    "    if multiple == True:\n",
    "        dataframe = merge_multi_label(dataframe)\n",
    "        \n",
    "    text_labels = dataframe['text'].to_numpy()\n",
    "    image_labels = dataframe['image'].to_numpy()\n",
    "    return text_labels, image_labels\n",
    "\n",
    "def create_text_data(path):\n",
    "    texts = []\n",
    "    text_paths = get_data_paths(path, '.txt')\n",
    "    \n",
    "    print('Read text data')\n",
    "    for text_path in tqdm(text_paths):\n",
    "        text = read_text_file(text_path).rstrip('\\n')\n",
    "        texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "def create_image_data(path):\n",
    "    images = []\n",
    "    invalid_indices = []\n",
    "    image_paths = get_data_paths(path, '.jpg')\n",
    "\n",
    "    print('Read image data')\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image, invalid_ID = read_image_file(image_path)\n",
    "        images.append(image)\n",
    "\n",
    "        if invalid_ID != -1:\n",
    "            invalid_indices.append(invalid_ID)\n",
    "            \n",
    "    images = np.array(images, dtype='uint8')\n",
    "    return images, invalid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3794fa6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.201011Z",
     "iopub.status.busy": "2024-12-29T18:56:59.200758Z",
     "iopub.status.idle": "2024-12-29T18:56:59.204340Z",
     "shell.execute_reply": "2024-12-29T18:56:59.203586Z"
    },
    "papermill": {
     "duration": 0.009784,
     "end_time": "2024-12-29T18:56:59.205537",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.195753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_invalid(data, indices):\n",
    "    valid_data = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in indices:\n",
    "            valid_data.append(data[i])\n",
    "    return valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39e9e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.215422Z",
     "iopub.status.busy": "2024-12-29T18:56:59.215192Z",
     "iopub.status.idle": "2024-12-29T18:56:59.219323Z",
     "shell.execute_reply": "2024-12-29T18:56:59.218576Z"
    },
    "papermill": {
     "duration": 0.010347,
     "end_time": "2024-12-29T18:56:59.220469",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.210122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_hdf5(path):\n",
    "    read_file = h5py.File(path, 'r')\n",
    "    \n",
    "    feature_names = list(read_file.keys())\n",
    "    loaded_data = []\n",
    "    \n",
    "    for name in feature_names:\n",
    "        dataset = read_file[name][:]\n",
    "        if dataset.dtype == np.dtype('object'):\n",
    "            dataset = np.array([x.decode('utf-8') for x in dataset])            \n",
    "        loaded_data.append((name, dataset))\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc93214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.230184Z",
     "iopub.status.busy": "2024-12-29T18:56:59.229984Z",
     "iopub.status.idle": "2024-12-29T18:56:59.234169Z",
     "shell.execute_reply": "2024-12-29T18:56:59.233609Z"
    },
    "papermill": {
     "duration": 0.010194,
     "end_time": "2024-12-29T18:56:59.235209",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.225015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_mvsa_data(path):\n",
    "    data = read_hdf5(path)\n",
    "    for x in data:\n",
    "        if x[0] == 'texts':\n",
    "            texts = x[1]\n",
    "        if x[0] == 'multimodal-labels':\n",
    "            labels = x[1]\n",
    "        if x[0] == 'text-labels':\n",
    "            text_labels = x[1]\n",
    "        if x[0] == 'image-labels':\n",
    "            image_labels = x[1]\n",
    "            \n",
    "    images_path = os.path.join(os.path.split(path)[0], os.path.split(path)[1].split('.')[0] + '-images.npz')\n",
    "    npzfile = np.load(images_path)\n",
    "    images = npzfile['arr_0']\n",
    "        \n",
    "    return texts, images, labels, text_labels, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e937bd77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:56:59.244821Z",
     "iopub.status.busy": "2024-12-29T18:56:59.244612Z",
     "iopub.status.idle": "2024-12-29T18:58:24.916758Z",
     "shell.execute_reply": "2024-12-29T18:58:24.916069Z"
    },
    "papermill": {
     "duration": 85.678642,
     "end_time": "2024-12-29T18:58:24.918304",
     "exception": false,
     "start_time": "2024-12-29T18:56:59.239662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read text data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [00:24<00:00, 195.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read image data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [01:00<00:00, 80.62it/s]\n"
     ]
    }
   ],
   "source": [
    "mvsa_single_texts = create_text_data(mvsa_single_data_path)\n",
    "mvsa_single_images, mvsa_single_images_invalid_indices = create_image_data(mvsa_single_data_path)\n",
    "mvsa_single_multimodal_labels = create_multimodal_labels(mvsa_single_label_path)\n",
    "mvsa_single_text_labels, mvsa_single_image_labels = create_original_labels(mvsa_single_label_path)\n",
    "num_mvsa_single = len(mvsa_single_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61091eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:24.995882Z",
     "iopub.status.busy": "2024-12-29T18:58:24.995561Z",
     "iopub.status.idle": "2024-12-29T18:58:25.000231Z",
     "shell.execute_reply": "2024-12-29T18:58:24.999400Z"
    },
    "papermill": {
     "duration": 0.044426,
     "end_time": "2024-12-29T18:58:25.001604",
     "exception": false,
     "start_time": "2024-12-29T18:58:24.957178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(sentiments):\n",
    "    \"\"\"\n",
    "    Converts an array of sentiments into a one-hot encoded array.\n",
    "    \n",
    "    Args:\n",
    "        sentiments (list): List of sentiments ('positive', 'negative', 'neutral').\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array with one-hot encoding for each sentiment.\n",
    "    \"\"\"\n",
    "    # Define the mapping for one-hot encoding\n",
    "    sentiment_map = {\n",
    "        'positive': [1, 0, 0],\n",
    "        'negative': [0, 1, 0],\n",
    "        'neutral': [0, 0, 1]\n",
    "    }\n",
    "    \n",
    "    # Create the one-hot encoded array\n",
    "    one_hot_array = np.array([sentiment_map[sentiment] for sentiment in sentiments])\n",
    "    return one_hot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade3e16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:25.076547Z",
     "iopub.status.busy": "2024-12-29T18:58:25.076239Z",
     "iopub.status.idle": "2024-12-29T18:58:25.082846Z",
     "shell.execute_reply": "2024-12-29T18:58:25.081938Z"
    },
    "papermill": {
     "duration": 0.045389,
     "end_time": "2024-12-29T18:58:25.084087",
     "exception": false,
     "start_time": "2024-12-29T18:58:25.038698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "mvsa_single_text_labels_one_hot = one_hot_encode(mvsa_single_text_labels)\n",
    "print(mvsa_single_text_labels_one_hot[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96958214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:25.158217Z",
     "iopub.status.busy": "2024-12-29T18:58:25.158011Z",
     "iopub.status.idle": "2024-12-29T18:58:25.164303Z",
     "shell.execute_reply": "2024-12-29T18:58:25.163383Z"
    },
    "papermill": {
     "duration": 0.044776,
     "end_time": "2024-12-29T18:58:25.165641",
     "exception": false,
     "start_time": "2024-12-29T18:58:25.120865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "['positive' 'positive' 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "mvsa_single_image_labels_one_hot = one_hot_encode(mvsa_single_image_labels)\n",
    "print(mvsa_single_image_labels_one_hot[0:5])\n",
    "print(mvsa_single_image_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e39add65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:25.242013Z",
     "iopub.status.busy": "2024-12-29T18:58:25.241753Z",
     "iopub.status.idle": "2024-12-29T18:58:25.245705Z",
     "shell.execute_reply": "2024-12-29T18:58:25.244993Z"
    },
    "papermill": {
     "duration": 0.042661,
     "end_time": "2024-12-29T18:58:25.246945",
     "exception": false,
     "start_time": "2024-12-29T18:58:25.204284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get duplicated text indices\n",
    "# mvsa_single_texts_unique_indices = np.unique(mvsa_single_texts, return_index=True)[1]\n",
    "# mvsa_single_texts_duplicated_indices = [i for i in range(num_mvsa_single) if i not in mvsa_single_texts_unique_indices]\n",
    "\n",
    "# Get invalid label indices\n",
    "mvsa_single_multimodal_labels_invalid_indices = [i for i in range(num_mvsa_single) if mvsa_single_multimodal_labels[i] == 'invalid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ae5361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:25.322897Z",
     "iopub.status.busy": "2024-12-29T18:58:25.322568Z",
     "iopub.status.idle": "2024-12-29T18:58:25.403564Z",
     "shell.execute_reply": "2024-12-29T18:58:25.402640Z"
    },
    "papermill": {
     "duration": 0.120682,
     "end_time": "2024-12-29T18:58:25.404958",
     "exception": false,
     "start_time": "2024-12-29T18:58:25.284276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text-image pair in MVSA-Single: 4869\n",
      "Number of invalid data in MVSA-Single: 358\n",
      "Number of text-image pair in MVSA-Single after removing invalid data: 4511\n"
     ]
    }
   ],
   "source": [
    "print('Number of text-image pair in MVSA-Single:', num_mvsa_single)\n",
    "\n",
    "mvsa_single_invalid_indices = []\n",
    "# mvsa_single_invalid_indices.extend(mvsa_single_texts_duplicated_indices)\n",
    "mvsa_single_invalid_indices.extend(mvsa_single_images_invalid_indices) # corrupted images\n",
    "mvsa_single_invalid_indices.extend(mvsa_single_multimodal_labels_invalid_indices)\n",
    "mvsa_single_invalid_indices = list(set(mvsa_single_invalid_indices))\n",
    "print('Number of invalid data in MVSA-Single:', len(mvsa_single_invalid_indices))\n",
    "\n",
    "mvsa_single_texts_valid = remove_invalid(mvsa_single_texts, mvsa_single_invalid_indices)\n",
    "mvsa_single_images_valid = remove_invalid(mvsa_single_images, mvsa_single_invalid_indices)\n",
    "mvsa_single_multimodal_labels_valid = remove_invalid(mvsa_single_multimodal_labels, mvsa_single_invalid_indices)\n",
    "mvsa_single_text_labels_valid = remove_invalid(mvsa_single_text_labels, mvsa_single_invalid_indices)\n",
    "mvsa_single_image_labels_valid = remove_invalid(mvsa_single_image_labels, mvsa_single_invalid_indices)\n",
    "\n",
    "num_mvsa_single_valid = len(mvsa_single_texts_valid)\n",
    "print('Number of text-image pair in MVSA-Single after removing invalid data:', num_mvsa_single_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa9d003a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:25.481824Z",
     "iopub.status.busy": "2024-12-29T18:58:25.481444Z",
     "iopub.status.idle": "2024-12-29T18:58:29.016667Z",
     "shell.execute_reply": "2024-12-29T18:58:29.015592Z"
    },
    "papermill": {
     "duration": 3.574914,
     "end_time": "2024-12-29T18:58:29.018123",
     "exception": false,
     "start_time": "2024-12-29T18:58:25.443209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# save and load check data\n",
    "with h5py.File('mvsa-single-{}.hdf5'.format(num_mvsa_single_valid), 'w') as f:\n",
    "    f.create_dataset('texts', data = mvsa_single_texts_valid)\n",
    "    f.create_dataset('images', data = mvsa_single_images_valid)\n",
    "    f.create_dataset('multimodal-labels', data = mvsa_single_multimodal_labels_valid)\n",
    "    f.create_dataset('text-labels', data = mvsa_single_text_labels_valid)\n",
    "    f.create_dataset('image-labels', data = mvsa_single_image_labels_valid)\n",
    "    \n",
    "np.savez('./mvsa-single-{}-images'.format(num_mvsa_single_valid), mvsa_single_images_valid)\n",
    "    \n",
    "mvsa_single_texts_loaded, mvsa_single_images_loaded, \\\n",
    "mvsa_single_multimodal_labels_loaded, mvsa_single_text_labels_loaded, \\\n",
    "mvsa_single_image_labels_loaded = load_mvsa_data('./mvsa-single-{}.hdf5'.format(num_mvsa_single_valid))\n",
    "\n",
    "print((mvsa_single_texts_valid == mvsa_single_texts_loaded).all())\n",
    "print((mvsa_single_images_valid == mvsa_single_images_loaded).all())\n",
    "print((mvsa_single_multimodal_labels_valid == mvsa_single_multimodal_labels_loaded).all())\n",
    "print((mvsa_single_text_labels_valid == mvsa_single_text_labels_loaded).all())\n",
    "print((mvsa_single_image_labels_valid == mvsa_single_image_labels_loaded).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f363993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:29.094704Z",
     "iopub.status.busy": "2024-12-29T18:58:29.094345Z",
     "iopub.status.idle": "2024-12-29T18:58:30.011383Z",
     "shell.execute_reply": "2024-12-29T18:58:30.010695Z"
    },
    "papermill": {
     "duration": 0.956897,
     "end_time": "2024-12-29T18:58:30.013022",
     "exception": false,
     "start_time": "2024-12-29T18:58:29.056125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mvsa_single_images = tf.transpose(mvsa_single_images, perm=[0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be357ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:30.137990Z",
     "iopub.status.busy": "2024-12-29T18:58:30.137664Z",
     "iopub.status.idle": "2024-12-29T18:58:34.569093Z",
     "shell.execute_reply": "2024-12-29T18:58:34.568066Z"
    },
    "papermill": {
     "duration": 4.472989,
     "end_time": "2024-12-29T18:58:34.570488",
     "exception": false,
     "start_time": "2024-12-29T18:58:30.097499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c86eed9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:34.648713Z",
     "iopub.status.busy": "2024-12-29T18:58:34.648353Z",
     "iopub.status.idle": "2024-12-29T18:58:43.097948Z",
     "shell.execute_reply": "2024-12-29T18:58:43.097075Z"
    },
    "papermill": {
     "duration": 8.490411,
     "end_time": "2024-12-29T18:58:43.099674",
     "exception": false,
     "start_time": "2024-12-29T18:58:34.609263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8508cdeb1e4a19b5226a6225b5ff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44684240a5ca4fe2974936bdaffe7468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ normalize (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ vit_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ normalize (\u001b[38;5;33mLambda\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ vit_model (\u001b[38;5;33mLambda\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m768\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m98,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,819</span> (386.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,819\u001b[0m (386.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,819</span> (386.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,819\u001b[0m (386.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TFViTModel\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_vit_model(num_classes):\n",
    "    # Input layer for images\n",
    "    image_input = Input(shape=(3,224, 224), name=\"image_input\", dtype=tf.float32)\n",
    "    \n",
    "    # Preprocessing: Normalize pixel values to the range [0, 1]\n",
    "    normalized_input = Lambda(lambda x: x / 255.0, name=\"normalize\")(image_input)\n",
    "    \n",
    "    # Load pre-trained Vision Transformer model\n",
    "    vit_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "    # Wrap `vit_model` to handle pixel_values explicitly\n",
    "    def vit_forward(inputs):\n",
    "        return vit_model(pixel_values=inputs).last_hidden_state\n",
    "\n",
    "    # Use Lambda layer to convert Keras tensor to TF tensor and pass to ViT\n",
    "    vit_output = Lambda(vit_forward, name=\"vit_model\", output_shape=(3,768))(normalized_input)\n",
    "\n",
    "    # Pool across the sequence length\n",
    "    pooled_output = GlobalAveragePooling1D()(vit_output)\n",
    "    \n",
    "    # Add dense layers for classification\n",
    "    x = Dense(128, activation=\"relu\")(pooled_output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=image_input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "num_classes = 3  # Replace with the number of classes in your dataset\n",
    "vit_model = create_vit_model(num_classes)\n",
    "\n",
    "# Print model summary\n",
    "vit_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d90686d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:43.190150Z",
     "iopub.status.busy": "2024-12-29T18:58:43.189758Z",
     "iopub.status.idle": "2024-12-29T18:58:43.203740Z",
     "shell.execute_reply": "2024-12-29T18:58:43.202922Z"
    },
    "papermill": {
     "duration": 0.058294,
     "end_time": "2024-12-29T18:58:43.206320",
     "exception": false,
     "start_time": "2024-12-29T18:58:43.148026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vit_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40ef3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:43.390437Z",
     "iopub.status.busy": "2024-12-29T18:58:43.390134Z",
     "iopub.status.idle": "2024-12-29T18:58:43.395117Z",
     "shell.execute_reply": "2024-12-29T18:58:43.394293Z"
    },
    "papermill": {
     "duration": 0.049756,
     "end_time": "2024-12-29T18:58:43.396296",
     "exception": false,
     "start_time": "2024-12-29T18:58:43.346540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4869, 3, 224, 224)\n",
      "(4869, 3)\n"
     ]
    }
   ],
   "source": [
    "print(mvsa_single_images.shape)  # Should be (4869, 3, 224, 224)\n",
    "print(mvsa_single_image_labels_one_hot.shape)  # Should match (4869, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56117b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:43.477159Z",
     "iopub.status.busy": "2024-12-29T18:58:43.476886Z",
     "iopub.status.idle": "2024-12-29T18:58:43.481173Z",
     "shell.execute_reply": "2024-12-29T18:58:43.480156Z"
    },
    "papermill": {
     "duration": 0.045761,
     "end_time": "2024-12-29T18:58:43.482666",
     "exception": false,
     "start_time": "2024-12-29T18:58:43.436905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4869, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(mvsa_single_images.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0450203a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:43.568742Z",
     "iopub.status.busy": "2024-12-29T18:58:43.568379Z",
     "iopub.status.idle": "2024-12-29T18:58:43.575769Z",
     "shell.execute_reply": "2024-12-29T18:58:43.575151Z"
    },
    "papermill": {
     "duration": 0.054957,
     "end_time": "2024-12-29T18:58:43.576961",
     "exception": false,
     "start_time": "2024-12-29T18:58:43.522004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ccf606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:58:43.661793Z",
     "iopub.status.busy": "2024-12-29T18:58:43.661443Z",
     "iopub.status.idle": "2024-12-29T19:02:46.263966Z",
     "shell.execute_reply": "2024-12-29T19:02:46.263229Z"
    },
    "papermill": {
     "duration": 242.647302,
     "end_time": "2024-12-29T19:02:46.265438",
     "exception": false,
     "start_time": "2024-12-29T18:58:43.618136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 341ms/step - accuracy: 0.5180 - loss: 1.0212 - val_accuracy: 0.5302 - val_loss: 0.9837\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.5762 - loss: 0.9097 - val_accuracy: 0.5340 - val_loss: 0.9530\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.5878 - loss: 0.8672 - val_accuracy: 0.5571 - val_loss: 0.9258\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.6291 - loss: 0.8172 - val_accuracy: 0.5623 - val_loss: 0.9024\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.6611 - loss: 0.7894 - val_accuracy: 0.5841 - val_loss: 0.8846\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.6802 - loss: 0.7610 - val_accuracy: 0.5879 - val_loss: 0.8673\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7152 - loss: 0.7115 - val_accuracy: 0.6110 - val_loss: 0.8534\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7190 - loss: 0.6990 - val_accuracy: 0.6149 - val_loss: 0.8486\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7384 - loss: 0.6573 - val_accuracy: 0.6316 - val_loss: 0.8361\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7485 - loss: 0.6544 - val_accuracy: 0.6483 - val_loss: 0.8296\n"
     ]
    }
   ],
   "source": [
    "# # Ensure input is in channels_first format for ViT: (batch_size, 3, 224, 224)\n",
    "# mvsa_single_images = tf.transpose(mvsa_single_images, perm=[0, 3, 1, 2])\n",
    "# print(mvsa_single_images.shape) \n",
    "\n",
    "# Initialize the model with a dummy input\n",
    "dummy_input = tf.random.normal((1, 3, 224, 224))  # Batch size 1\n",
    "_ = vit_model(dummy_input)\n",
    "\n",
    "\n",
    "try:\n",
    "    vit_model.fit(\n",
    "        mvsa_single_images[0:3895],\n",
    "        mvsa_single_image_labels_one_hot[0:3895],\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", e)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0e72fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T19:02:46.433177Z",
     "iopub.status.busy": "2024-12-29T19:02:46.432839Z",
     "iopub.status.idle": "2024-12-29T19:02:54.513219Z",
     "shell.execute_reply": "2024-12-29T19:02:54.512346Z"
    },
    "papermill": {
     "duration": 8.165302,
     "end_time": "2024-12-29T19:02:54.514859",
     "exception": false,
     "start_time": "2024-12-29T19:02:46.349557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 260ms/step - accuracy: 0.6343 - loss: 0.8345\n",
      "Test Loss: 0.8334760069847107\n",
      "Test Accuracy: 0.6166495084762573\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = vit_model.evaluate( mvsa_single_images[3896:], mvsa_single_image_labels_one_hot[3896:], batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8385971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T19:02:54.690816Z",
     "iopub.status.busy": "2024-12-29T19:02:54.690432Z",
     "iopub.status.idle": "2024-12-29T19:03:07.723578Z",
     "shell.execute_reply": "2024-12-29T19:03:07.722615Z"
    },
    "papermill": {
     "duration": 13.120472,
     "end_time": "2024-12-29T19:03:07.725110",
     "exception": false,
     "start_time": "2024-12-29T19:02:54.604638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 320ms/step\n",
      "Predicted classes: [0 2 0 1 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 1 2 0 0 0 0 0 0 0\n",
      " 2 2 1 1 0 0 1 0 0 1 2 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 1 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 1 0 0 2 0]\n",
      "True classes: [1 1 1 1 1 0 2 0 0 2 2 2 2 2 0 1 1 0 0 0 0 0 0 1 0 1 1 2 1 2 0 1 0 1 1 0 0\n",
      " 1 2 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 2 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 2 0 0 0 0 0 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the test images\n",
    "predictions = vit_model.predict(mvsa_single_images[3896:], batch_size=32)\n",
    "\n",
    "# Convert predictions from probabilities to class labels\n",
    "predicted_classes = tf.argmax(predictions, axis=1)  # Predicted class indices\n",
    "true_classes = tf.argmax(mvsa_single_image_labels_one_hot[3896:], axis=1)       # True class indices (if labels are one-hot)\n",
    "\n",
    "# Print a few predictions\n",
    "print(\"Predicted classes:\", predicted_classes.numpy()[:100])\n",
    "print(\"True classes:\", true_classes.numpy()[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a30d2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T19:03:07.898571Z",
     "iopub.status.busy": "2024-12-29T19:03:07.898228Z",
     "iopub.status.idle": "2024-12-29T19:03:07.902260Z",
     "shell.execute_reply": "2024-12-29T19:03:07.901627Z"
    },
    "papermill": {
     "duration": 0.090778,
     "end_time": "2024-12-29T19:03:07.903385",
     "exception": false,
     "start_time": "2024-12-29T19:03:07.812607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_images=mvsa_single_images[3896:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d5858f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T19:03:08.076673Z",
     "iopub.status.busy": "2024-12-29T19:03:08.076333Z",
     "iopub.status.idle": "2024-12-29T19:03:13.309194Z",
     "shell.execute_reply": "2024-12-29T19:03:13.308150Z"
    },
    "papermill": {
     "duration": 5.32122,
     "end_time": "2024-12-29T19:03:13.310591",
     "exception": false,
     "start_time": "2024-12-29T19:03:07.989371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.66      0.84      0.74       516\n",
      "    Negative       0.53      0.27      0.36       270\n",
      "     Neutral       0.51      0.50      0.51       187\n",
      "\n",
      "    accuracy                           0.62       973\n",
      "   macro avg       0.57      0.54      0.53       973\n",
      "weighted avg       0.60      0.62      0.59       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Make predictions\n",
    "predictions = vit_model.predict(test_images, batch_size=32)\n",
    "predicted_classes = tf.argmax(predictions, axis=1).numpy()  # Convert predictions to class indices\n",
    "true_classes = tf.argmax(mvsa_single_image_labels_one_hot[3896:], axis=1).numpy()       # Convert one-hot labels to class indices\n",
    "\n",
    "# Step 2: Generate classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=['Positive','Negative','Neutral'])\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2262518,
     "sourceId": 3792882,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 387.918478,
   "end_time": "2024-12-29T19:03:16.580082",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-29T18:56:48.661604",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "055b07b85ea54070a218654c72a828d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10ed17fb035f4416bfa1f45757022caa",
       "placeholder": "​",
       "style": "IPY_MODEL_5f79ef4d105c4b718c0933bec9dea2fe",
       "tabbable": null,
       "tooltip": null,
       "value": " 502/502 [00:00&lt;00:00, 44.0kB/s]"
      }
     },
     "10ed17fb035f4416bfa1f45757022caa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "186f18bb74e64c04a409d03e0c9baa37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c9d1a4bdfcc4dfe8e129991af100439": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44684240a5ca4fe2974936bdaffe7468": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d55a09cc0cf64b38ae8e02d0a24862a2",
        "IPY_MODEL_6e6b6ce635024555a76db4454f0cda24",
        "IPY_MODEL_7839ee7d308948c786c54b3957956a99"
       ],
       "layout": "IPY_MODEL_a565968350b64b0a8159ee1c52157065",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4ef03ffad0334529af7fec4b16b8c122": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d23fd270b384eb8b6d4d5ba19f57f81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d8508cdeb1e4a19b5226a6225b5ff91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_83ae2c1d6b174aaeae04dd33c308eb53",
        "IPY_MODEL_81c05dadd24f46148e9d4bdede33c577",
        "IPY_MODEL_055b07b85ea54070a218654c72a828d3"
       ],
       "layout": "IPY_MODEL_2c9d1a4bdfcc4dfe8e129991af100439",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5f79ef4d105c4b718c0933bec9dea2fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6e6b6ce635024555a76db4454f0cda24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ddee3c0e7186401db9d561cbb51dd8ca",
       "max": 345579424.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d384459ba64a4d98b6250744013a2a59",
       "tabbable": null,
       "tooltip": null,
       "value": 345579424.0
      }
     },
     "7839ee7d308948c786c54b3957956a99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_186f18bb74e64c04a409d03e0c9baa37",
       "placeholder": "​",
       "style": "IPY_MODEL_bcba21465809446aaed381de70cb0f93",
       "tabbable": null,
       "tooltip": null,
       "value": " 346M/346M [00:01&lt;00:00, 239MB/s]"
      }
     },
     "81bbe78af40147cdb5ae1d0575e4da58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "81c05dadd24f46148e9d4bdede33c577": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89fbef5c4563489db2a648a31c01ea10",
       "max": 502.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_81bbe78af40147cdb5ae1d0575e4da58",
       "tabbable": null,
       "tooltip": null,
       "value": 502.0
      }
     },
     "83ae2c1d6b174aaeae04dd33c308eb53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d31e89287a6a445a937ab1194064c97a",
       "placeholder": "​",
       "style": "IPY_MODEL_5d23fd270b384eb8b6d4d5ba19f57f81",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "89fbef5c4563489db2a648a31c01ea10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a565968350b64b0a8159ee1c52157065": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcba21465809446aaed381de70cb0f93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d31e89287a6a445a937ab1194064c97a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d384459ba64a4d98b6250744013a2a59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d55a09cc0cf64b38ae8e02d0a24862a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ef03ffad0334529af7fec4b16b8c122",
       "placeholder": "​",
       "style": "IPY_MODEL_e0a0d832e01d41c7a8f155b62b57d0cf",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "ddee3c0e7186401db9d561cbb51dd8ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0a0d832e01d41c7a8f155b62b57d0cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
